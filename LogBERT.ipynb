{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Peo9TZb9gcKe",
        "outputId": "24d05aae-7365-4ff7-e0b4-6f6bba453a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aimlops_c3_g7_capstone_loganalysis'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 129 (delta 37), reused 102 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (129/129), 13.83 MiB | 7.37 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "Updating files: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sahu-manas/aimlops_c3_g7_capstone_loganalysis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/aimlops_c3_g7_capstone_loganalysis')"
      ],
      "metadata": {
        "id": "da_iwaV3g2gD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M6Wqutvdg_nT",
        "outputId": "ff505b5c-54bc-4045-ad0c-04743dd4e297"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (5.5.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 6)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 7)) (2.32.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 11)) (4.66.6)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (6.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 3)) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 4)) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 7)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 7)) (2024.8.30)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 9)) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (1.3.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 10)) (3.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (24.0.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->-r /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/requirements.txt (line 2)) (0.2.13)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1hPJNEfhN1A",
        "outputId": "d6150b31-c896-4032-c8b4-a91127b8fb19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_process.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TQW7yXqhTzS",
        "outputId": "7961522c-dba1-430e-a808-b6979c40ecdc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing file: ./data/openstack.log\n",
            "Total size after encoding is 207636 207820\n",
            "Parsing done. [Time taken: 0:00:26.569001]\n",
            "{'2311ba9a': 1, 'e38ba92e': 2, '3896e936': 3, '72a32043': 4, 'c583951f': 5, '72f56ddb': 6, 'b6030ec8': 7, '2d179c5a': 8, '3f98d481': 9, 'f290a191': 10, '899b89e9': 11, '47f4680b': 12, '0935b192': 13, '6deed83e': 14, 'e51c49ab': 15, '3b70c34a': 16, '186a4531': 17, '6b44cd99': 18, 'afea322e': 19, '652a820e': 20, '3f256a7a': 21, '989b7898': 22, 'fb3c7a48': 23, '29b363a7': 24, '66acd71e': 25, 'abdcd27a': 26, '12b67311': 27, 'bc0f0d5b': 28, '3f80eae5': 29, '4d622637': 30, '9be245ad': 31, '9f12feda': 32, 'f2d59697': 33, '1499a277': 34, '63e82264': 35, 'f5c027b5': 36, '44223c81': 37, 'c3abe8d5': 38, 'c28159fd': 39}\n",
            "Loading ./output/openstack.log_structured.csv\n",
            "207636it [00:09, 22046.68it/s]\n",
            "100% 2069/2069 [03:01<00:00, 11.41it/s]\n",
            "openstack sampling done\n",
            "4it [00:00, 11297.79it/s]\n",
            "{'544fd51c-4edc-4780-baae-ba1d80a0acfc': 1, 'ae651dff-c7ad-43d6-ac96-bbcd820ccca8': 1, 'a445709b-6ad0-40ec-8860-bec60b6ca0c2': 1, '1643649d-2f42-4303-bfcd-7798baec19f9': 1}\n",
            "                             InstanceId                                      EventSequence  Label\n",
            "0  b9000564-fe1a-409b-b8cc-1e88b294cd1d  [5, 5, 12, 16, 5, 11, 10, 12, 5, 15, 22, 6, 11...      0\n",
            "1  96abccce-8d1f-4e07-b6d1-4b2ab87e23b4  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...      0\n",
            "2  b562ef10-ba2d-48ae-bf4a-18666cba4a51  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...      0\n",
            "3  78dc1847-8848-49cc-933e-9239b12c9dcf  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...      0\n",
            "4  95960536-049b-41f6-9049-05fc479b6a7c  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...      0\n",
            "                             InstanceId                                      EventSequence  Label\n",
            "0  b9000564-fe1a-409b-b8cc-1e88b294cd1d  [5, 5, 12, 16, 5, 11, 10, 12, 5, 15, 22, 6, 11...    0.0\n",
            "1  96abccce-8d1f-4e07-b6d1-4b2ab87e23b4  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...    0.0\n",
            "2  b562ef10-ba2d-48ae-bf4a-18666cba4a51  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...    0.0\n",
            "3  78dc1847-8848-49cc-933e-9239b12c9dcf  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...    0.0\n",
            "4  95960536-049b-41f6-9049-05fc479b6a7c  [17, 18, 19, 8, 9, 8, 9, 6, 1, 6, 5, 5, 12, 16...    0.0\n",
            "normal size 2065, abnormal size 4, training size 1652\n",
            "generate train test data done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python logbert.py vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWsccRi6iTqh",
        "outputId": "3034b58d-1f97-402d-a6f5-d03b2225ad19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n",
            "features logkey:True time: False\n",
            "\n",
            "mask ratio 0.65\n",
            "arguments Namespace(vocab_size=None, encoding='utf-8', min_freq=1, mode='vocab')\n",
            "Building Vocab\n",
            "\r  0% 0/1652 [00:00<?, ?it/s]\r100% 1652/1652 [00:00<00:00, 154193.43it/s]\n",
            "VOCAB SIZE: 23\n",
            "save vocab in ./output/vocab.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python logbert.py train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdki7tS6icjz",
        "outputId": "a73ce5f4-2785-43f6-f79e-e1291c96a7ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n",
            "features logkey:True time: False\n",
            "\n",
            "mask ratio 0.65\n",
            "arguments Namespace(mode='train')\n",
            "Save options parameters\n",
            "Loading vocab ./output/vocab.pkl\n",
            "vocab Size:  23\n",
            "\n",
            "Loading Train Dataset\n",
            "before filtering short session\n",
            "train size  1487\n",
            "valid size  165\n",
            "========================================\n",
            "\r  0% 0/1652 [00:00<?, ?it/s]\r100% 1652/1652 [00:00<00:00, 53274.93it/s]\n",
            "========================================\n",
            "Num of train seqs 1485\n",
            "Num of valid seqs 165\n",
            "========================================\n",
            "\n",
            "Loading valid Dataset\n",
            "Creating Dataloader\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Building BERT model\n",
            "Creating BERT Trainer\n",
            "Total Parameters: 2121752\n",
            "Training Start\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:01<00:00, 30.19it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 48.99it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 0 | phase: train, loss=3.46002473520196\n",
            "logkey loss: 3.3389006904933765, hyper loss: 1.2112404082132422\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 0 | phase: valid, loss=3.387178897857666\n",
            "logkey loss: 3.2667799472808836, hyper loss: 1.2039897918701172\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 86.11it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 44.44it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 1 | phase: train, loss=3.2961604957995205\n",
            "logkey loss: 3.1763734402863877, hyper loss: 1.1978705110757246\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 1 | phase: valid, loss=3.1709643363952638\n",
            "logkey loss: 3.0513867378234862, hyper loss: 1.1957756519317626\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 54.81it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 34.20it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 2 | phase: train, loss=3.0419219991435176\n",
            "logkey loss: 2.9249570680701216, hyper loss: 1.1696493521980618\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 2 | phase: valid, loss=2.9338439464569093\n",
            "logkey loss: 2.8172570705413817, hyper loss: 1.165868616104126\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 86.60it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 46.73it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 3 | phase: train, loss=2.8378311551135518\n",
            "logkey loss: 2.7248646487360415, hyper loss: 1.129665239997532\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 3 | phase: valid, loss=2.727526903152466\n",
            "logkey loss: 2.6156522274017333, hyper loss: 1.1187464237213134\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 85.57it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 43.92it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 4 | phase: train, loss=2.621935756310173\n",
            "logkey loss: 2.514024045156396, hyper loss: 1.079117212606513\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 4 | phase: valid, loss=2.520704746246338\n",
            "logkey loss: 2.4154406547546388, hyper loss: 1.0526407480239868\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 88.52it/s] \n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 44.41it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 5 | phase: train, loss=2.3646512394366055\n",
            "logkey loss: 2.262453690819118, hyper loss: 1.021975400655166\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 5 | phase: valid, loss=2.2354535102844237\n",
            "logkey loss: 2.1341670036315916, hyper loss: 1.0128647804260253\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 88.19it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 37.14it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 6 | phase: train, loss=2.0381040910015935\n",
            "logkey loss: 1.9416607540586721, hyper loss: 0.9644335365813711\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 6 | phase: valid, loss=1.8708455324172975\n",
            "logkey loss: 1.7759727954864502, hyper loss: 0.9487271666526794\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 53.62it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 31.82it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 7 | phase: train, loss=1.6681566290233447\n",
            "logkey loss: 1.5771316186241482, hyper loss: 0.9102501169494961\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 7 | phase: valid, loss=1.5122843265533448\n",
            "logkey loss: 1.4215219497680665, hyper loss: 0.907624113559723\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 86.82it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 43.87it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 8 | phase: train, loss=1.377622866112253\n",
            "logkey loss: 1.2908665408258853, hyper loss: 0.8675632334273794\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 8 | phase: valid, loss=1.2616788148880005\n",
            "logkey loss: 1.17722544670105, hyper loss: 0.8445335507392884\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 83.40it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 47.20it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 9 | phase: train, loss=1.166061124076014\n",
            "logkey loss: 1.0843153427476468, hyper loss: 0.8174578728883163\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 9 | phase: valid, loss=1.0980426788330078\n",
            "logkey loss: 1.016523015499115, hyper loss: 0.8151966333389282\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 88.15it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 43.70it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 10 | phase: train, loss=1.0201758988525556\n",
            "logkey loss: 0.9412878972032795, hyper loss: 0.7888800411120706\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 10 | phase: valid, loss=0.9610325217247009\n",
            "logkey loss: 0.8824410915374756, hyper loss: 0.7859142184257507\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 81.74it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 46.96it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 11 | phase: train, loss=0.8996595636658047\n",
            "logkey loss: 0.823018711546193, hyper loss: 0.766408525083376\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 11 | phase: valid, loss=0.8513862490653992\n",
            "logkey loss: 0.7758163094520569, hyper loss: 0.7556993365287781\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 14.594323439429896\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 57.88it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 30.70it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 12 | phase: train, loss=0.8178006112575531\n",
            "logkey loss: 0.7420760056246882, hyper loss: 0.7572460692861805\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 12 | phase: valid, loss=0.7992244124412536\n",
            "logkey loss: 0.7208222031593323, hyper loss: 0.7840221762657166\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 14.619490278234542\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 84.94it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 42.26it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 13 | phase: train, loss=0.7560986371144004\n",
            "logkey loss: 0.6818176352459452, hyper loss: 0.7428100744019384\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 13 | phase: valid, loss=0.7413401365280151\n",
            "logkey loss: 0.6652384757995605, hyper loss: 0.7610165357589722\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 14.525011784504642\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 82.88it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 45.76it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 14 | phase: train, loss=0.6871046359124391\n",
            "logkey loss: 0.6140787711609965, hyper loss: 0.7302586475144262\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 14 | phase: valid, loss=0.6805453658103943\n",
            "logkey loss: 0.6071686387062073, hyper loss: 0.7337671637535095\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 14.324099643019789\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 83.14it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 44.40it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 15 | phase: train, loss=0.6361097149226976\n",
            "logkey loss: 0.5647952394640964, hyper loss: 0.7131447779095691\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 15 | phase: valid, loss=0.5996883630752563\n",
            "logkey loss: 0.5281730890274048, hyper loss: 0.7151526689529419\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 14.198112517318183\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 83.68it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 41.58it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 16 | phase: train, loss=0.5859375913505969\n",
            "logkey loss: 0.5163398229557535, hyper loss: 0.695977648963099\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 16 | phase: valid, loss=0.5623331844806672\n",
            "logkey loss: 0.49075846672058104, hyper loss: 0.7157472372055054\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 14.100263004961038\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 78.43it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 32.98it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 17 | phase: train, loss=0.550999448351238\n",
            "logkey loss: 0.48377701964067377, hyper loss: 0.6722242508245551\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 17 | phase: valid, loss=0.54831303358078\n",
            "logkey loss: 0.4807374179363251, hyper loss: 0.6757561802864075\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 13.776495765870365\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 82.99it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 43.05it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 18 | phase: train, loss=0.5050450498643129\n",
            "logkey loss: 0.4398300038731616, hyper loss: 0.6521504663902781\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 18 | phase: valid, loss=0.5310216188430786\n",
            "logkey loss: 0.4656087398529053, hyper loss: 0.6541287660598755\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 13.600395298733073\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "\n",
            "\n",
            "start calculate center\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/46 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 46/46 [00:00<00:00, 82.55it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "  0% 0/5 [00:00<?, ?it/s]/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "100% 5/5 [00:00<00:00, 47.84it/s]\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 19 | phase: train, loss=0.48230591481146606\n",
            "logkey loss: 0.41926618892213574, hyper loss: 0.6303972744423411\n",
            "\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "Epoch: 19 | phase: valid, loss=0.49050077199935915\n",
            "logkey loss: 0.4261613070964813, hyper loss: 0.6433947086334229\n",
            "\n",
            "Log saved\n",
            " Model Saved on: ./output/bert/best_bert.pth\n",
            "best radius 13.405041429078418\n",
            "Save best center ./output/bert/best_center.pt\n",
            "save total dist:  ./output/bert/best_total_dist.pt\n",
            "Figure(640x480)\n",
            "plot done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python logbert.py predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIrkKuKVizI8",
        "outputId": "f68dff61-89c6-4e4a-ab2c-9063b69dfee3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device cuda\n",
            "features logkey:True time: False\n",
            "\n",
            "mask ratio 0.65\n",
            "arguments Namespace(mean=0, std=1, mode='predict')\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/predict_log.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load(self.model_path)\n",
            "model_path: ./output/bert/best_bert.pth\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/predict_log.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  center_dict = torch.load(self.model_dir + \"best_center.pt\")\n",
            "test normal predicting\n",
            "\r0it [00:00, ?it/s]\r413it [00:00, 61837.27it/s]\n",
            "test_normal size: 413\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 19 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 20 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 16 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 18 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 16 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 21 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 24 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 1, # of masked_tokens: 19 , # of total logkey 30, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 12 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 24 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 25 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 12 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 12 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 24 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 12 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 13 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 13 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 12 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 12 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 25 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 13 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 14 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 23 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 22 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 21 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 13 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 15 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 19 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_normal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 16 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test abnormal predicting\n",
            "4it [00:00, 24174.66it/s]\n",
            "test_abnormal size: 4\n",
            "/content/aimlops_c3_g7_capstone_loganalysis/openstack_loganalysis/../logbert_pytorch/dataset/log_dataset.py:130: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  output[\"time_input\"] = torch.tensor(output[\"time_input\"], dtype=torch.float)\n",
            "test_abnormal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 18 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_abnormal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 20 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_abnormal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 13 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "test_abnormal, #time anomaly: 0 # of undetected_tokens: 0, # of masked_tokens: 17 , # of total logkey 29, deepSVDD_label: 0 \n",
            "\n",
            "Saving test normal results\n",
            "Saving test abnormal results\n",
            "Saving test normal errors\n",
            "Saving test abnormal results\n",
            "best threshold: 0, best threshold ratio: 0\n",
            "TP: 0, TN: 0, FP: 0, FN: 0\n",
            "Precision: 0.00%, Recall: 0.00%, F1-measure: 0.00%\n",
            "elapsed_time: 2.410243511199951\n"
          ]
        }
      ]
    }
  ]
}